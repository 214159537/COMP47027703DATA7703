{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "PCA  can  be  implemented  very  simply  in  Matlab  or  Python.   Given  a  dataset  (as  amatrix X), the covariance matrix can be found using the Matlab covariance function (cov(X)).Then, the eigenvectors and eigenvalues of this covariance matrix are the principal component(vectors) and principal values respectively.  The eigenvalues reflect the amount of varianceaccounted  for  by  each  principal  component  and  are  ordered.   To  perform  dimensionalityreduction (e.g.  down to 2 dimensions), we need to multiply X by the two eigenvectors withthe largest corresponding eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, n_components=2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the MNIST dataset, run your PCA function on the data. \n",
    "1. Produce a plot of the data in the space spanned by the first two principal com-ponents.  Colour each point by its class.\n",
    "2. What percentage of the data variance is accounted for by the first two principalcomponents?\n",
    "3. From the results, produce a Scree graph similar to that shown in Fig 6.2 of theAlpaydin text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the procedure above using the Swissroll and Diabetes datasets.  For MNIST,compare a plot visualising only 2 digits with a plot visualising 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE\n",
    "Run the t-SNE algorithm on 6000 datapoints from the MNIST dataset:\n",
    "2. load(’mnist_train.mat’);\n",
    "3. idx = unidrnd(60000, 6000, 1);\n",
    "4. x = train_X(idx, :);\n",
    "5. labels = train_labels(idx);\n",
    "6. tsne(x, labels, 2, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one or two sentences, explain how t-SNE differs from SNE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one or two sentences, explain lines 3, 4 and 5 in the code snippet above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a screenshot of the 2-dimensional visualisation after 300 iterations.  Plot theerror at each iteration up to 300 iterations in steps of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In  3-4  sentences,  explain  lines  51-53  and  lines  87-89  in  tsnep.m  in  relation  to  anyfeatures you observe in your plot.  Why has the code been written in this way?  (Hint- read the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment out lines 51-53 and 87-89.  Run t-SNE for 300 iterations for perplexity valuesranging from 10 to 300 in steps of 10.  Produce a 3D plot with perplexity and iterationson the horizontal axis and cost on the vertical axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After consulting your plot, comment on the following statement:A lower cost valuealways produces a better visualisation.Choose a suitable perplexity value and providethe visualisation in 2D space after 300 iterations for your chosen perplexity.  Comparethis with your result in (Q3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run t-SNE (without PCA as a preprocessing step and with lines 51−53 and 87−89uncommented) on the Swissroll and Diabetes datasets.  Comment on the visualisationsit produces.  Provide the parameters you used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Resources:\n",
    "* How to use t-SNE Effectively - http://distill.pub/2016/misread-tsne/One of the first articles on the new research platform called Distill.\n",
    "* Gradient-Based Optimization - Chapter 4.3 of Deep Learning available onlinehttp://www.deeplearningbook.org/contents/numerical.htmlWe will be revisiting gradient descent later when training neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
